name: emr-venv
on:
  pull_request:
    branches: [main]
env:
  BUCKET_NAME : ${{ secrets.BUCKET_NAME_PYTEST }}
  AWS_REGION : ${{ secrets.AWS_REGION }}
  BUCKET_NAME_RAW_DATA: ${{ secrets.BUCKET_NAME_RAW_DATA }}
  FOLDER_NAME_RAW_DATA : ${{ secrets.FOLDER_NAME_RAW_DATA }}
# permission can be added at job level or workflow level
permissions:
      id-token: write   # This is required for requesting the JWT
      contents: read    # This is required for actions/checkout
jobs:
  emr:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: '3.9'
      - name: Set Node.js 16.x
        uses: actions/setup-node@v3
        with:
          node-version: 16.x
      - name: Run install
        uses: borales/actions-yarn@v4
        with:
          cmd: install # will run `yarn install` command
      - name: configure aws credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          role-to-assume: ${{ secrets.ROLE_TO_ASSUME }}
          role-session-name: ${{ secrets.ROLE_SESSION_NAME }}
          aws-region: ${{ env.AWS_REGION }}


      - name:  run docker build
        run:   DOCKER_BUILDKIT=1 docker build --output . .
      - uses: secrethub/actions/env-export@v0.2.1
        env:
          BUCKET_NAME_RAW_DATA: ${{ secrets.BUCKET_NAME_RAW_DATA }}
          FOLDER_NAME_RAW_DATA: ${{ secrets.FOLDER_NAME_RAW_DATA }}
          TEST: ${{ env.TEST }}


      - name: upload to s3
        run: |            
          aws s3 cp ./pyspark_deps_github.tar.gz s3://${{ secrets.BUCKET_NAME_PYTEST }}/emr_serverless/code/spark_dependency/
          aws s3 cp ./eks_ml_pipeline/emr_job.py s3://${{ secrets.BUCKET_NAME_PYTEST }}/emr_serverless/code/emr_entry_point/