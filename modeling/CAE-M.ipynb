{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building out CAE-M\n",
    "Research paper link\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install keras_self_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import json\n",
    "import sys\n",
    "import statsmodels.api as sm\n",
    "import os\n",
    "import keras\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from autoencoder_model_dish_5g import Autoencoder_Model_Dish_5g\n",
    "from keras_self_attention import SeqSelfAttention, SeqWeightedAttention\n",
    "from keras.losses import mse\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import _pickle as cPickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##global variable\n",
    "# H = 6\n",
    "# t = 10\n",
    "# T = 60\n",
    "# M = 6\n",
    "\n",
    "\n",
    "\n",
    "h = 4\n",
    "timePerTemporalSlice = 12\n",
    "\n",
    "\n",
    "timesteps = h * timePerTemporalSlice\n",
    "time_steps = h * timePerTemporalSlice\n",
    "batch_size = 6\n",
    "n_samples = batch_size*100\n",
    "features = ['node_cpu_utilization','node_memory_utilization','node_network_total_bytes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets read in our training sample set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df_full = pd.read_parquet('/root/healthy_clusters_node_month.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>InstanceId</th>\n",
       "      <th>ClusterName</th>\n",
       "      <th>node_cpu_utilization</th>\n",
       "      <th>node_cpu_limit</th>\n",
       "      <th>node_cpu_request</th>\n",
       "      <th>node_cpu_usage_total</th>\n",
       "      <th>node_memory_utilization</th>\n",
       "      <th>node_memory_request</th>\n",
       "      <th>node_memory_limit</th>\n",
       "      <th>node_network_rx_bytes</th>\n",
       "      <th>node_network_rx_dropped</th>\n",
       "      <th>node_network_rx_errors</th>\n",
       "      <th>node_network_rx_packets</th>\n",
       "      <th>node_network_total_bytes</th>\n",
       "      <th>node_network_tx_bytes</th>\n",
       "      <th>node_network_tx_dropped</th>\n",
       "      <th>node_network_tx_errors</th>\n",
       "      <th>node_network_tx_packets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1654235914008</td>\n",
       "      <td>i-01470d8d8e7b4fd2f</td>\n",
       "      <td>nk-ndc-eks-cluster-dev-usw2-az1-dev-ncm01</td>\n",
       "      <td>2.905276</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>1266.0</td>\n",
       "      <td>116.211031</td>\n",
       "      <td>9.394841</td>\n",
       "      <td>998244352</td>\n",
       "      <td>16476487680</td>\n",
       "      <td>26133.384568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.334264</td>\n",
       "      <td>56498.252063</td>\n",
       "      <td>30364.867495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.300537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1654235917104</td>\n",
       "      <td>i-0b36e8825c482f762</td>\n",
       "      <td>nk-ndc-eks-cluster-dev-usw2-az1-dev-ncm01</td>\n",
       "      <td>1.836838</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>1066.0</td>\n",
       "      <td>73.473529</td>\n",
       "      <td>7.296163</td>\n",
       "      <td>851443712</td>\n",
       "      <td>16476487680</td>\n",
       "      <td>5812.096097</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.781011</td>\n",
       "      <td>13940.610609</td>\n",
       "      <td>8128.514512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.814785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1654232669947</td>\n",
       "      <td>i-01470d8d8e7b4fd2f</td>\n",
       "      <td>nk-ndc-eks-cluster-dev-usw2-az1-dev-ncm01</td>\n",
       "      <td>2.950336</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>1266.0</td>\n",
       "      <td>118.013421</td>\n",
       "      <td>9.399117</td>\n",
       "      <td>998244352</td>\n",
       "      <td>16476487680</td>\n",
       "      <td>24538.169434</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.939803</td>\n",
       "      <td>54629.097665</td>\n",
       "      <td>30090.928231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.904324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1654232681444</td>\n",
       "      <td>i-0b36e8825c482f762</td>\n",
       "      <td>nk-ndc-eks-cluster-dev-usw2-az1-dev-ncm01</td>\n",
       "      <td>1.858162</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>1066.0</td>\n",
       "      <td>74.326468</td>\n",
       "      <td>7.295069</td>\n",
       "      <td>851443712</td>\n",
       "      <td>16476487680</td>\n",
       "      <td>5451.981961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.206624</td>\n",
       "      <td>13392.905270</td>\n",
       "      <td>7940.923309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.632175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1654235970093</td>\n",
       "      <td>i-093473861e74eaf2d</td>\n",
       "      <td>mt-ndc-eks-cluster-dev-mt-use1</td>\n",
       "      <td>0.942944</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>1266.0</td>\n",
       "      <td>150.871041</td>\n",
       "      <td>4.956222</td>\n",
       "      <td>998244352</td>\n",
       "      <td>65902239744</td>\n",
       "      <td>42229.503040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>251.934982</td>\n",
       "      <td>90291.404482</td>\n",
       "      <td>48061.901442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>251.558398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Timestamp           InstanceId  \\\n",
       "0  1654235914008  i-01470d8d8e7b4fd2f   \n",
       "1  1654235917104  i-0b36e8825c482f762   \n",
       "2  1654232669947  i-01470d8d8e7b4fd2f   \n",
       "3  1654232681444  i-0b36e8825c482f762   \n",
       "4  1654235970093  i-093473861e74eaf2d   \n",
       "\n",
       "                                 ClusterName  node_cpu_utilization  \\\n",
       "0  nk-ndc-eks-cluster-dev-usw2-az1-dev-ncm01              2.905276   \n",
       "1  nk-ndc-eks-cluster-dev-usw2-az1-dev-ncm01              1.836838   \n",
       "2  nk-ndc-eks-cluster-dev-usw2-az1-dev-ncm01              2.950336   \n",
       "3  nk-ndc-eks-cluster-dev-usw2-az1-dev-ncm01              1.858162   \n",
       "4             mt-ndc-eks-cluster-dev-mt-use1              0.942944   \n",
       "\n",
       "   node_cpu_limit  node_cpu_request  node_cpu_usage_total  \\\n",
       "0          4000.0            1266.0            116.211031   \n",
       "1          4000.0            1066.0             73.473529   \n",
       "2          4000.0            1266.0            118.013421   \n",
       "3          4000.0            1066.0             74.326468   \n",
       "4         16000.0            1266.0            150.871041   \n",
       "\n",
       "   node_memory_utilization  node_memory_request  node_memory_limit  \\\n",
       "0                 9.394841            998244352        16476487680   \n",
       "1                 7.296163            851443712        16476487680   \n",
       "2                 9.399117            998244352        16476487680   \n",
       "3                 7.295069            851443712        16476487680   \n",
       "4                 4.956222            998244352        65902239744   \n",
       "\n",
       "   node_network_rx_bytes  node_network_rx_dropped  node_network_rx_errors  \\\n",
       "0           26133.384568                      0.0                     0.0   \n",
       "1            5812.096097                      0.0                     0.0   \n",
       "2           24538.169434                      0.0                     0.0   \n",
       "3            5451.981961                      0.0                     0.0   \n",
       "4           42229.503040                      0.0                     0.0   \n",
       "\n",
       "   node_network_rx_packets  node_network_total_bytes  node_network_tx_bytes  \\\n",
       "0                87.334264              56498.252063           30364.867495   \n",
       "1                22.781011              13940.610609            8128.514512   \n",
       "2                86.939803              54629.097665           30090.928231   \n",
       "3                21.206624              13392.905270            7940.923309   \n",
       "4               251.934982              90291.404482           48061.901442   \n",
       "\n",
       "   node_network_tx_dropped  node_network_tx_errors  node_network_tx_packets  \n",
       "0                      0.0                     0.0                86.300537  \n",
       "1                      0.0                     0.0                22.814785  \n",
       "2                      0.0                     0.0                86.904324  \n",
       "3                      0.0                     0.0                21.632175  \n",
       "4                      0.0                     0.0               251.558398  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['Timestamp','InstanceId','node_cpu_utilization','node_memory_utilization','node_network_total_bytes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "training_df = training_df_full.drop(training_df_full.columns.difference(columns_to_keep),1, inplace=False)\n",
    "training_df['Timestamp'] = pd.to_datetime(training_df['Timestamp'], unit='ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2636965"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = training_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = training_df.copy()\n",
    "training_df = training_df[training_df.InstanceId != 'i-0b36e8825c482f762']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN DATASET: Build out Dataset for training on many nodes\n",
    "\n",
    "now we are starting to build out a training dataset for two nodes. This will prove our understanding of how to model can generalize across many EC2 instances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for normalization\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_dfs =[]\n",
    "for instance in training_df['InstanceId'].unique():\n",
    "    if(len(training_df[training_df.InstanceId == instance]) >60):\n",
    "        instance_dfs.append(training_df[training_df.InstanceId == instance].sort_values(by='Timestamp')\\\n",
    "                            .reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 48, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import random \n",
    "\n",
    "x_train = np.zeros((n_samples,time_steps,len(features)))\n",
    "for b in range(n_samples):\n",
    "    \n",
    "    ##pick random df, and normalize\n",
    "    df = random.choice(instance_dfs)\n",
    "    df = df.drop(columns = ['InstanceId'])\n",
    "    df = df.set_index('Timestamp')\n",
    "    df = df.sort_index()\n",
    "    df[features] = scaler.fit_transform(df[features])\n",
    "    \n",
    "    \n",
    "    \n",
    "    sample = np.zeros((n_samples,len(features)))\n",
    "    ##make sure length of df is atleast 40\n",
    "#     print(len(df))\n",
    "    first_time = random.choice(range(len(df)-time_steps))\n",
    "    df.head()\n",
    "    sample = df[features].iloc[first_time:first_time+time_steps]\n",
    "    x_train[b] = sample\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our xtrain shape has the following properties: (sample size, time steps, numFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST DATASET: Build out Dataset for testing on one node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df[test_df.InstanceId == 'i-0b36e8825c482f762']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>InstanceId</th>\n",
       "      <th>node_cpu_utilization</th>\n",
       "      <th>node_memory_utilization</th>\n",
       "      <th>node_network_total_bytes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-06-03 05:58:37.104</td>\n",
       "      <td>i-0b36e8825c482f762</td>\n",
       "      <td>1.836838</td>\n",
       "      <td>7.296163</td>\n",
       "      <td>13940.610609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-06-03 05:04:41.444</td>\n",
       "      <td>i-0b36e8825c482f762</td>\n",
       "      <td>1.858162</td>\n",
       "      <td>7.295069</td>\n",
       "      <td>13392.905270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-06-03 05:59:35.385</td>\n",
       "      <td>i-0b36e8825c482f762</td>\n",
       "      <td>1.824157</td>\n",
       "      <td>7.296387</td>\n",
       "      <td>14073.509120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2022-06-03 05:05:34.448</td>\n",
       "      <td>i-0b36e8825c482f762</td>\n",
       "      <td>1.821361</td>\n",
       "      <td>7.297928</td>\n",
       "      <td>14987.560707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2022-06-03 06:00:39.866</td>\n",
       "      <td>i-0b36e8825c482f762</td>\n",
       "      <td>1.811754</td>\n",
       "      <td>7.299718</td>\n",
       "      <td>13253.130119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Timestamp           InstanceId  node_cpu_utilization  \\\n",
       "1  2022-06-03 05:58:37.104  i-0b36e8825c482f762              1.836838   \n",
       "3  2022-06-03 05:04:41.444  i-0b36e8825c482f762              1.858162   \n",
       "9  2022-06-03 05:59:35.385  i-0b36e8825c482f762              1.824157   \n",
       "11 2022-06-03 05:05:34.448  i-0b36e8825c482f762              1.821361   \n",
       "17 2022-06-03 06:00:39.866  i-0b36e8825c482f762              1.811754   \n",
       "\n",
       "    node_memory_utilization  node_network_total_bytes  \n",
       "1                  7.296163              13940.610609  \n",
       "3                  7.295069              13392.905270  \n",
       "9                  7.296387              14073.509120  \n",
       "11                 7.297928              14987.560707  \n",
       "17                 7.299718              13253.130119  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "## drop the instanceId\n",
    "test_df = test_df.drop(\"InstanceId\",1, inplace=False)\n",
    "\n",
    "\n",
    "##set timestamp as the index\n",
    "test_df = test_df.set_index('Timestamp')\n",
    "\n",
    "##normalize test_df \n",
    "test_df[features] = scaler.fit_transform(test_df[features])\n",
    "\n",
    "\n",
    "##ensure the data is sorted!!\n",
    "test_df = test_df.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAE-M Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 4\n",
    "t = 12\n",
    "T = H * t\n",
    "M = 6\n",
    "F = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##global variable\n",
    "\n",
    "h = 2\n",
    "\n",
    "timePerTemporalSlice = 6\n",
    "\n",
    "\n",
    "timesteps = h * timePerTemporalSlice \n",
    "\n",
    "time_steps = h * timePerTemporalSlice\n",
    "\n",
    "batch_size = 6\n",
    "\n",
    "n_samples = batch_size*100\n",
    "\n",
    "features = ['node_cpu_utilization','node_memory_utilization','node_network_total_bytes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 3, 48)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain = x_train.reshape(n_samples,F,T)\n",
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we build input_reshaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"input_reshaper\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sample_F_N (InputLayer)     [(None, 3, 48)]           0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 4, 3, 12)          0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sample_F_N = keras.Input(shape=(F,T), name=\"sample_F_N\")\n",
    "\n",
    "sample_H_F_T = layers.Reshape((H,F,t), input_shape=(F,T)) (sample_F_N)\n",
    "\n",
    "input_reshaper = keras.Model(sample_F_N, sample_H_F_T, name=\"input_reshaper\")\n",
    "input_reshaper.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next we build encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_input_F_T_Channels_  [(None, 3, 12, 1)]       0         \n",
      " h1 (InputLayer)                                                 \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 3, 12, 32)         160       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 3, 12, 32)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 3, 12, 64)         8256      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 3, 12, 64)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,416\n",
      "Trainable params: 8,416\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_input = keras.Input(shape=(F,t,1), name=\"encoder_input_F_T_Channels_h1\")\n",
    "x = layers.Conv2D(32, 2, activation=\"relu\", padding = 'same')(encoder_input)\n",
    "x = layers.MaxPooling2D((2,2), strides = 1, padding = 'same')(x)\n",
    "x = layers.Conv2D(64, 2, activation=\"relu\", padding = 'same')(x)\n",
    "encoder_output = layers.MaxPooling2D((2,2), strides = 1, padding = 'same')(x)\n",
    "encoder = keras.Model(encoder_input, encoder_output , name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next we build decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ecoded (InputLayer)         [(None, 3, 12, 64)]       0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 3, 12, 64)        16448     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 3, 12, 32)        8224      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 3, 12, 1)         129       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 3, 12)             0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,801\n",
      "Trainable params: 24,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_input = keras.Input(shape=(F, t, 64), name=\"ecoded\")\n",
    "x = layers.Conv2DTranspose(64, 2, activation=\"relu\",padding = 'same')(decoder_input)\n",
    "x = layers.Conv2DTranspose(32, 2, activation=\"relu\",padding = 'same')(x)\n",
    "decoded_slice = layers.Conv2DTranspose(1, 2, activation=\"relu\",padding = 'same')(x)\n",
    "decoded_slice = layers.Reshape((F,t), input_shape=(F,t,1)) (decoded_slice)\n",
    "decoder = keras.Model(decoder_input, decoded_slice, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next we build BILSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BiLSTM\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " BiLSTM_input (InputLayer)   [(None, 3, 2340)]         0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 3, 1024)          11685888  \n",
      " l)                                                              \n",
      "                                                                 \n",
      " seq_weighted_attention (Seq  (None, 1024)             1025      \n",
      " WeightedAttention)                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2340)              2398500   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,085,413\n",
      "Trainable params: 14,085,413\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "BiLSTM_input = keras.Input(shape=(H-1,F*t*65), name=\"BiLSTM_input\")\n",
    "\n",
    "x = layers.Bidirectional(layers.LSTM(512,return_sequences=True))(BiLSTM_input)\n",
    "x = SeqWeightedAttention(H-1)(x)\n",
    "BiLSTM_output = layers.Dense(F*t*65)(x)\n",
    "\n",
    "BiLSTM = keras.Model(BiLSTM_input, BiLSTM_output, name=\"BiLSTM\")\n",
    "BiLSTM.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next we build Linear Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"linear_predictor\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " linear_input (InputLayer)   [(None, 7020)]            0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2340)              16429140  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,429,140\n",
      "Trainable params: 16,429,140\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "linear_input = keras.Input(shape=((H-1)*F*t*65), name=\"linear_input\")\n",
    "linear_output = layers.Dense(F*t*65)(linear_input)\n",
    "linear_predictor = keras.Model(linear_input, linear_output, name=\"linear_predictor\")\n",
    "linear_predictor.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we assemble CAE-M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H = 4\n",
    "# t = 12\n",
    "# T = H * t\n",
    "# M = 6\n",
    "# F = 3\n",
    "\"\"\" INPUT TIME \"\"\"\n",
    "##input for CAE-M, with shape (F,T). This input gets reshaped into (H,F,t)\n",
    "wrongshape_input = keras.Input(shape=(F,T), name=\"sample\")\n",
    "reshaped_input = input_reshaper(wrongshape_input)\n",
    "\n",
    "\"\"\" AUTOENCODER TIME \"\"\"\n",
    "##LATENT SPACE Zf\n",
    "encoded_temporal_slices = [encoder(reshaped_input[:,temporal_slice,:,:]) for temporal_slice in range(H)]\n",
    "##OUTPUT OF AUTOENCODER\n",
    "decoded_temporal_slices = [decoder(encoded_temporal_slices[temporal_slice]) for temporal_slice in range(H)]\n",
    "decoded_for_output = layers.Concatenate(name = 'decoded_for_output')(decoded_temporal_slices)\n",
    "\n",
    "\n",
    "##CREATE Z = Zf + Zr\n",
    "## Zr is residual of the autoencoder\n",
    "residuals  = [reshaped_input[:,temporal_slices,:,:] - decoded_temporal_slices[temporal_slices] for temporal_slices in range(H) ]\n",
    "# residuals = tf.convert_to_tensor(residuals)\n",
    "residuals = [layers.Reshape((3,12,1))(residuals[temporal_slices])  for temporal_slices in range(H)]\n",
    "Z = [layers.Concatenate()([encoded_temporal_slices[temporal_slices],residuals[temporal_slices]]) for temporal_slices in range(H) ] \n",
    "Z_flattened = [ layers.Flatten()(Z[temporal_slices]) for temporal_slices in range(H)]\n",
    "\n",
    "\n",
    "##CREATE THE LABEL for CAE-M forecasters\n",
    "Y = Z_flattened[-1]\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" BILSTM TIME \"\"\"\n",
    "##RESHAPE FOR INPUT FOR LSTM -->> NEED shape [BATCHSIZE, H-1, F*t*65] and then predict to the BiLSTM\n",
    "Z_flattened = Z_flattened[:-1]\n",
    "Z_flattened = [ layers.Reshape((1,2340))(Z_flattened[temporal_slices]) for temporal_slices in range(H-1)]\n",
    "\n",
    "Z_flattened = layers.Concatenate(name = 'z_flatten_concat', axis =1)(Z_flattened)\n",
    "## Feed BILSTM\n",
    "Y_hat = BiLSTM(Z_flattened)\n",
    "\n",
    "\n",
    "\"\"\" LINEAR TIME \"\"\"\n",
    "##RESHAPE input again for the linear predictor --> NEED shape [Batchsize, (H-1)*F*t*65] and then feed to linear predictor\n",
    "Z_flattened_stack = layers.Flatten(name = 'Z_flattened_for_linear')(Z_flattened)\n",
    "Z_hat = linear_predictor(Z_flattened_stack)\n",
    "\n",
    "\"\"\" CAE-M TIME \"\"\"\n",
    "CAEM = keras.Model(inputs = wrongshape_input,  outputs = [wrongshape_input,decoded_for_output,Y,Y_hat,Z_hat],\n",
    "                          name=\"CAE-M\")\n",
    "\n",
    "\"\"\" Loss TIME \"\"\"\n",
    "\n",
    "loss = mse(wrongshape_input, decoded_for_output) + (.5 *mse(Y_hat, Y)) + (.5 *mse(Z_hat, Y))\n",
    "CAEM.add_loss(loss)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CAE-M\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " sample (InputLayer)            [(None, 3, 48)]      0           []                               \n",
      "                                                                                                  \n",
      " input_reshaper (Functional)    (None, 4, 3, 12)     0           ['sample[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None, 3, 12)       0           ['input_reshaper[0][0]']         \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1 (Sl  (None, 3, 12)       0           ['input_reshaper[0][0]']         \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2 (Sl  (None, 3, 12)       0           ['input_reshaper[0][0]']         \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " encoder (Functional)           (None, 3, 12, 64)    8416        ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 , 'tf.__operators__.getitem_1[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'tf.__operators__.getitem_2[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'tf.__operators__.getitem_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " decoder (Functional)           (None, 3, 12)        24801       ['encoder[0][0]',                \n",
      "                                                                  'encoder[1][0]',                \n",
      "                                                                  'encoder[2][0]',                \n",
      "                                                                  'encoder[3][0]']                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_4 (Sl  (None, 3, 12)       0           ['input_reshaper[0][0]']         \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_5 (Sl  (None, 3, 12)       0           ['input_reshaper[0][0]']         \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_6 (Sl  (None, 3, 12)       0           ['input_reshaper[0][0]']         \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.math.subtract (TFOpLambda)  (None, 3, 12)        0           ['tf.__operators__.getitem_4[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'decoder[0][0]']                \n",
      "                                                                                                  \n",
      " tf.math.subtract_1 (TFOpLambda  (None, 3, 12)       0           ['tf.__operators__.getitem_5[0][0\n",
      " )                                                               ]',                              \n",
      "                                                                  'decoder[1][0]']                \n",
      "                                                                                                  \n",
      " tf.math.subtract_2 (TFOpLambda  (None, 3, 12)       0           ['tf.__operators__.getitem_6[0][0\n",
      " )                                                               ]',                              \n",
      "                                                                  'decoder[2][0]']                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_3 (Sl  (None, 3, 12)       0           ['input_reshaper[0][0]']         \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)            (None, 3, 12, 1)     0           ['tf.math.subtract[0][0]']       \n",
      "                                                                                                  \n",
      " reshape_3 (Reshape)            (None, 3, 12, 1)     0           ['tf.math.subtract_1[0][0]']     \n",
      "                                                                                                  \n",
      " reshape_4 (Reshape)            (None, 3, 12, 1)     0           ['tf.math.subtract_2[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 3, 12, 65)    0           ['encoder[0][0]',                \n",
      "                                                                  'reshape_2[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 3, 12, 65)    0           ['encoder[1][0]',                \n",
      "                                                                  'reshape_3[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 3, 12, 65)    0           ['encoder[2][0]',                \n",
      "                                                                  'reshape_4[0][0]']              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_7 (Sl  (None, 3, 12)       0           ['input_reshaper[0][0]']         \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2340)         0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 2340)         0           ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 2340)         0           ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " tf.math.subtract_3 (TFOpLambda  (None, 3, 12)       0           ['tf.__operators__.getitem_7[0][0\n",
      " )                                                               ]',                              \n",
      "                                                                  'decoder[3][0]']                \n",
      "                                                                                                  \n",
      " reshape_6 (Reshape)            (None, 1, 2340)      0           ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " reshape_7 (Reshape)            (None, 1, 2340)      0           ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_8 (Reshape)            (None, 1, 2340)      0           ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_5 (Reshape)            (None, 3, 12, 1)     0           ['tf.math.subtract_3[0][0]']     \n",
      "                                                                                                  \n",
      " z_flatten_concat (Concatenate)  (None, 3, 2340)     0           ['reshape_6[0][0]',              \n",
      "                                                                  'reshape_7[0][0]',              \n",
      "                                                                  'reshape_8[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 3, 12, 65)    0           ['encoder[3][0]',                \n",
      "                                                                  'reshape_5[0][0]']              \n",
      "                                                                                                  \n",
      " Z_flattened_for_linear (Flatte  (None, 7020)        0           ['z_flatten_concat[0][0]']       \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " decoded_for_output (Concatenat  (None, 3, 48)       0           ['decoder[0][0]',                \n",
      " e)                                                               'decoder[1][0]',                \n",
      "                                                                  'decoder[2][0]',                \n",
      "                                                                  'decoder[3][0]']                \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 2340)         0           ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " BiLSTM (Functional)            (None, 2340)         14085413    ['z_flatten_concat[0][0]']       \n",
      "                                                                                                  \n",
      " linear_predictor (Functional)  (None, 2340)         16429140    ['Z_flattened_for_linear[0][0]'] \n",
      "                                                                                                  \n",
      " tf.convert_to_tensor_1 (TFOpLa  (None, 2340)        0           ['flatten_3[0][0]']              \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.cast_1 (TFOpLambda)         (None, 2340)         0           ['BiLSTM[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.convert_to_tensor (TFOpLamb  (None, 3, 48)       0           ['decoded_for_output[0][0]']     \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.cast (TFOpLambda)           (None, 3, 48)        0           ['sample[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.math.squared_difference_1 (  (None, 2340)        0           ['tf.convert_to_tensor_1[0][0]', \n",
      " TFOpLambda)                                                      'tf.cast_1[0][0]']              \n",
      "                                                                                                  \n",
      " tf.convert_to_tensor_2 (TFOpLa  (None, 2340)        0           ['flatten_3[0][0]']              \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.cast_2 (TFOpLambda)         (None, 2340)         0           ['linear_predictor[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.squared_difference (TF  (None, 3, 48)       0           ['tf.convert_to_tensor[0][0]',   \n",
      " OpLambda)                                                        'tf.cast[0][0]']                \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_1 (TFOpLam  (None,)             0           ['tf.math.squared_difference_1[0]\n",
      " bda)                                                            [0]']                            \n",
      "                                                                                                  \n",
      " tf.math.squared_difference_2 (  (None, 2340)        0           ['tf.convert_to_tensor_2[0][0]', \n",
      " TFOpLambda)                                                      'tf.cast_2[0][0]']              \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean (TFOpLambd  (None, 3)           0           ['tf.math.squared_difference[0][0\n",
      " a)                                                              ]']                              \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None,)              0           ['tf.math.reduce_mean_1[0][0]']  \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_2 (TFOpLam  (None,)             0           ['tf.math.squared_difference_2[0]\n",
      " bda)                                                            [0]']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 3)           0           ['tf.math.reduce_mean[0][0]',    \n",
      " da)                                                              'tf.math.multiply[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.multiply_1 (TFOpLambda  (None,)             0           ['tf.math.reduce_mean_2[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 3)           0           ['tf.__operators__.add[0][0]',   \n",
      " mbda)                                                            'tf.math.multiply_1[0][0]']     \n",
      "                                                                                                  \n",
      " add_loss (AddLoss)             (None, 3)            0           ['tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,547,770\n",
      "Trainable params: 30,547,770\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "CAEM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAEM.compile(optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "180/180 [==============================] - 14s 58ms/step - loss: 0.0502 - val_loss: 0.0172\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 10s 55ms/step - loss: 0.0138 - val_loss: 0.0096\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 10s 55ms/step - loss: 0.0096 - val_loss: 0.0084\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 10s 56ms/step - loss: 0.0080 - val_loss: 0.0065\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 10s 56ms/step - loss: 0.0071 - val_loss: 0.0057\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 10s 57ms/step - loss: 0.0064 - val_loss: 0.0053\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 10s 56ms/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 10s 55ms/step - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 10s 53ms/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 10s 53ms/step - loss: 0.0049 - val_loss: 0.0038\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 10s 53ms/step - loss: 0.0047 - val_loss: 0.0035\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0045 - val_loss: 0.0033\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 10s 55ms/step - loss: 0.0043 - val_loss: 0.0032\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 10s 55ms/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 10s 55ms/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 10s 55ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 10s 55ms/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 10s 55ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 24/100\n",
      "180/180 [==============================] - 10s 55ms/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 27/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 28/100\n",
      "180/180 [==============================] - 10s 53ms/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 29/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 30/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 31/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 32/100\n",
      "180/180 [==============================] - 10s 53ms/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 33/100\n",
      "180/180 [==============================] - 10s 55ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 34/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 35/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 36/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 37/100\n",
      "180/180 [==============================] - 10s 53ms/step - loss: 0.0028 - val_loss: 0.0019\n",
      "Epoch 38/100\n",
      "180/180 [==============================] - 10s 55ms/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 39/100\n",
      "180/180 [==============================] - 10s 55ms/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 40/100\n",
      "180/180 [==============================] - 10s 53ms/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 41/100\n",
      "180/180 [==============================] - 10s 53ms/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 42/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 43/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 44/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 45/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 46/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 47/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 48/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 49/100\n",
      "180/180 [==============================] - 10s 55ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 50/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 51/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 52/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 53/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 54/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 55/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 56/100\n",
      "180/180 [==============================] - 10s 53ms/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 57/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 58/100\n",
      "180/180 [==============================] - 10s 55ms/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 59/100\n",
      "180/180 [==============================] - 10s 55ms/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 60/100\n",
      "180/180 [==============================] - 10s 55ms/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 61/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 62/100\n",
      "180/180 [==============================] - 10s 53ms/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 63/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 64/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 65/100\n",
      "180/180 [==============================] - 10s 53ms/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 66/100\n",
      "180/180 [==============================] - 10s 53ms/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 67/100\n",
      "180/180 [==============================] - 10s 53ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 68/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 69/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 70/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 71/100\n",
      "180/180 [==============================] - 10s 55ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 72/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 73/100\n",
      "180/180 [==============================] - 10s 55ms/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 74/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 75/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 76/100\n",
      "180/180 [==============================] - 10s 55ms/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 77/100\n",
      "180/180 [==============================] - 10s 55ms/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 78/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0022 - val_loss: 0.0061\n",
      "Epoch 79/100\n",
      "180/180 [==============================] - 10s 55ms/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 80/100\n",
      "180/180 [==============================] - 10s 55ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 81/100\n",
      "180/180 [==============================] - 10s 55ms/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 82/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 83/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 84/100\n",
      "180/180 [==============================] - 10s 56ms/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 85/100\n",
      "180/180 [==============================] - 10s 55ms/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 86/100\n",
      "180/180 [==============================] - 10s 55ms/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 87/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 88/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 89/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 90/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 91/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 92/100\n",
      "180/180 [==============================] - 10s 55ms/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 93/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 94/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 95/100\n",
      "180/180 [==============================] - 10s 56ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 96/100\n",
      "180/180 [==============================] - 10s 55ms/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 97/100\n",
      "180/180 [==============================] - 10s 55ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 98/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 99/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 100/100\n",
      "180/180 [==============================] - 10s 54ms/step - loss: 0.0021 - val_loss: 0.0013\n"
     ]
    }
   ],
   "source": [
    "history = CAEM.fit(\n",
    "                xtrain,\n",
    "                epochs=100,\n",
    "                validation_split=.1,\n",
    "                batch_size=3)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.4xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
