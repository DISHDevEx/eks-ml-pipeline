{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA Demo\n",
    "\n",
    " Vinayak Sharma\n",
    "  \n",
    " This notebook aims to train an autoencoder on univariate timeseries data from EKS Performance metrics for MANY NODES. The training data is 'non-anomalous'. \n",
    "\n",
    " The model and implementation techniques can be found in the following github: https://github.com/emerelte/kad\n",
    " \n",
    " The research paper that this work is based on can be found here: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9925210"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##global variable\n",
    "timesteps = 12\n",
    "time_steps = 12\n",
    "batch_size = 6\n",
    "n_samples = batch_size*100\n",
    "features = ['node_cpu_utilization','node_memory_utilization','node_network_total_bytes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r /root/eks-ml-pipeline/modeling/kad/kad/requirements.txt\n",
    "# # # !pip install keras\n",
    "# # # !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib as mpl\n",
    "# mpl.rcParams.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import json\n",
    "import sys\n",
    "import statsmodels.api as sm\n",
    "import os\n",
    "# import keras\n",
    "# from keras import layers\n",
    "# import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pca_ad_dish_5g import pca_ad_dish_5g\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import _pickle as cPickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "# import warnings\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from tensorflow import keras\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import layers\n",
    "# from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets read in our training sample set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df_full = pd.read_parquet('/root/healthy_clusters_node_month.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>InstanceId</th>\n",
       "      <th>ClusterName</th>\n",
       "      <th>node_cpu_utilization</th>\n",
       "      <th>node_cpu_limit</th>\n",
       "      <th>node_cpu_request</th>\n",
       "      <th>node_cpu_usage_total</th>\n",
       "      <th>node_memory_utilization</th>\n",
       "      <th>node_memory_request</th>\n",
       "      <th>node_memory_limit</th>\n",
       "      <th>node_network_rx_bytes</th>\n",
       "      <th>node_network_rx_dropped</th>\n",
       "      <th>node_network_rx_errors</th>\n",
       "      <th>node_network_rx_packets</th>\n",
       "      <th>node_network_total_bytes</th>\n",
       "      <th>node_network_tx_bytes</th>\n",
       "      <th>node_network_tx_dropped</th>\n",
       "      <th>node_network_tx_errors</th>\n",
       "      <th>node_network_tx_packets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1654235914008</td>\n",
       "      <td>i-01470d8d8e7b4fd2f</td>\n",
       "      <td>nk-ndc-eks-cluster-dev-usw2-az1-dev-ncm01</td>\n",
       "      <td>2.905276</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>1266.0</td>\n",
       "      <td>116.211031</td>\n",
       "      <td>9.394841</td>\n",
       "      <td>998244352</td>\n",
       "      <td>16476487680</td>\n",
       "      <td>26133.384568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.334264</td>\n",
       "      <td>56498.252063</td>\n",
       "      <td>30364.867495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.300537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1654235917104</td>\n",
       "      <td>i-0b36e8825c482f762</td>\n",
       "      <td>nk-ndc-eks-cluster-dev-usw2-az1-dev-ncm01</td>\n",
       "      <td>1.836838</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>1066.0</td>\n",
       "      <td>73.473529</td>\n",
       "      <td>7.296163</td>\n",
       "      <td>851443712</td>\n",
       "      <td>16476487680</td>\n",
       "      <td>5812.096097</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.781011</td>\n",
       "      <td>13940.610609</td>\n",
       "      <td>8128.514512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.814785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1654232669947</td>\n",
       "      <td>i-01470d8d8e7b4fd2f</td>\n",
       "      <td>nk-ndc-eks-cluster-dev-usw2-az1-dev-ncm01</td>\n",
       "      <td>2.950336</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>1266.0</td>\n",
       "      <td>118.013421</td>\n",
       "      <td>9.399117</td>\n",
       "      <td>998244352</td>\n",
       "      <td>16476487680</td>\n",
       "      <td>24538.169434</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.939803</td>\n",
       "      <td>54629.097665</td>\n",
       "      <td>30090.928231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.904324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1654232681444</td>\n",
       "      <td>i-0b36e8825c482f762</td>\n",
       "      <td>nk-ndc-eks-cluster-dev-usw2-az1-dev-ncm01</td>\n",
       "      <td>1.858162</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>1066.0</td>\n",
       "      <td>74.326468</td>\n",
       "      <td>7.295069</td>\n",
       "      <td>851443712</td>\n",
       "      <td>16476487680</td>\n",
       "      <td>5451.981961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.206624</td>\n",
       "      <td>13392.905270</td>\n",
       "      <td>7940.923309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.632175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1654235970093</td>\n",
       "      <td>i-093473861e74eaf2d</td>\n",
       "      <td>mt-ndc-eks-cluster-dev-mt-use1</td>\n",
       "      <td>0.942944</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>1266.0</td>\n",
       "      <td>150.871041</td>\n",
       "      <td>4.956222</td>\n",
       "      <td>998244352</td>\n",
       "      <td>65902239744</td>\n",
       "      <td>42229.503040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>251.934982</td>\n",
       "      <td>90291.404482</td>\n",
       "      <td>48061.901442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>251.558398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Timestamp           InstanceId  \\\n",
       "0  1654235914008  i-01470d8d8e7b4fd2f   \n",
       "1  1654235917104  i-0b36e8825c482f762   \n",
       "2  1654232669947  i-01470d8d8e7b4fd2f   \n",
       "3  1654232681444  i-0b36e8825c482f762   \n",
       "4  1654235970093  i-093473861e74eaf2d   \n",
       "\n",
       "                                 ClusterName  node_cpu_utilization  \\\n",
       "0  nk-ndc-eks-cluster-dev-usw2-az1-dev-ncm01              2.905276   \n",
       "1  nk-ndc-eks-cluster-dev-usw2-az1-dev-ncm01              1.836838   \n",
       "2  nk-ndc-eks-cluster-dev-usw2-az1-dev-ncm01              2.950336   \n",
       "3  nk-ndc-eks-cluster-dev-usw2-az1-dev-ncm01              1.858162   \n",
       "4             mt-ndc-eks-cluster-dev-mt-use1              0.942944   \n",
       "\n",
       "   node_cpu_limit  node_cpu_request  node_cpu_usage_total  \\\n",
       "0          4000.0            1266.0            116.211031   \n",
       "1          4000.0            1066.0             73.473529   \n",
       "2          4000.0            1266.0            118.013421   \n",
       "3          4000.0            1066.0             74.326468   \n",
       "4         16000.0            1266.0            150.871041   \n",
       "\n",
       "   node_memory_utilization  node_memory_request  node_memory_limit  \\\n",
       "0                 9.394841            998244352        16476487680   \n",
       "1                 7.296163            851443712        16476487680   \n",
       "2                 9.399117            998244352        16476487680   \n",
       "3                 7.295069            851443712        16476487680   \n",
       "4                 4.956222            998244352        65902239744   \n",
       "\n",
       "   node_network_rx_bytes  node_network_rx_dropped  node_network_rx_errors  \\\n",
       "0           26133.384568                      0.0                     0.0   \n",
       "1            5812.096097                      0.0                     0.0   \n",
       "2           24538.169434                      0.0                     0.0   \n",
       "3            5451.981961                      0.0                     0.0   \n",
       "4           42229.503040                      0.0                     0.0   \n",
       "\n",
       "   node_network_rx_packets  node_network_total_bytes  node_network_tx_bytes  \\\n",
       "0                87.334264              56498.252063           30364.867495   \n",
       "1                22.781011              13940.610609            8128.514512   \n",
       "2                86.939803              54629.097665           30090.928231   \n",
       "3                21.206624              13392.905270            7940.923309   \n",
       "4               251.934982              90291.404482           48061.901442   \n",
       "\n",
       "   node_network_tx_dropped  node_network_tx_errors  node_network_tx_packets  \n",
       "0                      0.0                     0.0                86.300537  \n",
       "1                      0.0                     0.0                22.814785  \n",
       "2                      0.0                     0.0                86.904324  \n",
       "3                      0.0                     0.0                21.632175  \n",
       "4                      0.0                     0.0               251.558398  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['Timestamp','InstanceId','node_cpu_utilization','node_memory_utilization','node_network_total_bytes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "training_df = training_df_full.drop(training_df_full.columns.difference(columns_to_keep),1, inplace=False)\n",
    "training_df['Timestamp'] = pd.to_datetime(training_df['Timestamp'], unit='ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2636965"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = training_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = training_df.copy()\n",
    "training_df = training_df[training_df.InstanceId != 'i-0b36e8825c482f762']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN DATASET: Build out Dataset for training on many nodes\n",
    "\n",
    "now we are starting to build out a training dataset for two nodes. This will prove our understanding of how to model can generalize across many EC2 instances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for normalization\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 12, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "instance_dfs =[]\n",
    "for instance in training_df['InstanceId'].unique():\n",
    "    instance_dfs.append(training_df[training_df.InstanceId == instance].sort_values(by='Timestamp')\\\n",
    "                        .reset_index(drop=True))\n",
    "\n",
    "import random \n",
    "\n",
    "x_train = np.zeros((n_samples,time_steps,len(features)))\n",
    "for b in range(n_samples):\n",
    "    \n",
    "    ##pick random df, and normalize\n",
    "    df = random.choice(instance_dfs)\n",
    "    df = df.drop(columns = ['InstanceId'])\n",
    "    df = df.set_index('Timestamp')\n",
    "    df = df.sort_index()\n",
    "    df[features] = scaler.fit_transform(df[features])\n",
    "    \n",
    "    \n",
    "    \n",
    "    sample = np.zeros((n_samples,len(features)))\n",
    "    ##make sure length of df is atleast 40\n",
    "    first_time = random.choice(range(len(df)-time_steps))\n",
    "    df.head()\n",
    "    sample = df[features].iloc[first_time:first_time+time_steps]\n",
    "    x_train[b] = sample\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our xtrain shape has the following properties: (sample size, time steps, numFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST DATASET: Build out Dataset for testing on one node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df[test_df.InstanceId == 'i-0b36e8825c482f762']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>InstanceId</th>\n",
       "      <th>node_cpu_utilization</th>\n",
       "      <th>node_memory_utilization</th>\n",
       "      <th>node_network_total_bytes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-06-03 05:58:37.104</td>\n",
       "      <td>i-0b36e8825c482f762</td>\n",
       "      <td>1.836838</td>\n",
       "      <td>7.296163</td>\n",
       "      <td>13940.610609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-06-03 05:04:41.444</td>\n",
       "      <td>i-0b36e8825c482f762</td>\n",
       "      <td>1.858162</td>\n",
       "      <td>7.295069</td>\n",
       "      <td>13392.905270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-06-03 05:59:35.385</td>\n",
       "      <td>i-0b36e8825c482f762</td>\n",
       "      <td>1.824157</td>\n",
       "      <td>7.296387</td>\n",
       "      <td>14073.509120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2022-06-03 05:05:34.448</td>\n",
       "      <td>i-0b36e8825c482f762</td>\n",
       "      <td>1.821361</td>\n",
       "      <td>7.297928</td>\n",
       "      <td>14987.560707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2022-06-03 06:00:39.866</td>\n",
       "      <td>i-0b36e8825c482f762</td>\n",
       "      <td>1.811754</td>\n",
       "      <td>7.299718</td>\n",
       "      <td>13253.130119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Timestamp           InstanceId  node_cpu_utilization  \\\n",
       "1  2022-06-03 05:58:37.104  i-0b36e8825c482f762              1.836838   \n",
       "3  2022-06-03 05:04:41.444  i-0b36e8825c482f762              1.858162   \n",
       "9  2022-06-03 05:59:35.385  i-0b36e8825c482f762              1.824157   \n",
       "11 2022-06-03 05:05:34.448  i-0b36e8825c482f762              1.821361   \n",
       "17 2022-06-03 06:00:39.866  i-0b36e8825c482f762              1.811754   \n",
       "\n",
       "    node_memory_utilization  node_network_total_bytes  \n",
       "1                  7.296163              13940.610609  \n",
       "3                  7.295069              13392.905270  \n",
       "9                  7.296387              14073.509120  \n",
       "11                 7.297928              14987.560707  \n",
       "17                 7.299718              13253.130119  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "## drop the instanceId\n",
    "test_df = test_df.drop(\"InstanceId\",1, inplace=False)\n",
    "\n",
    "\n",
    "##set timestamp as the index\n",
    "test_df = test_df.set_index('Timestamp')\n",
    "\n",
    "##normalize test_df \n",
    "test_df[features] = scaler.fit_transform(test_df[features])\n",
    "\n",
    "\n",
    "##ensure the data is sorted!!\n",
    "test_df = test_df.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model = pca_ad_dish_5g(num_of_features=3, number_of_temporal_slices=3, timesteps_per_slice=4, n_modes_to_delete=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals,ed_errors,encode_decode_maps = pca_model.train(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1800, 3)\n"
     ]
    }
   ],
   "source": [
    "print(ed_errors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model.save_vs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then we test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model = pca_ad_dish_5g(num_of_features=3, number_of_temporal_slices=3, timesteps_per_slice=4, n_modes_to_delete=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model.load_in_vs('vs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test = []\n",
    "res_test = []\n",
    "\n",
    "for i in range(0,len(test_df),timesteps):\n",
    "    if(i + timesteps < len(test_df)):\n",
    "        sample_topredict_on = test_df.iloc[i:i+timesteps]\n",
    "        x_test = np.array(sample_topredict_on.to_numpy())\n",
    "        x_test = x_test.reshape(1,-1,3)\n",
    "        y_hat,residuals = pca_model.test(x_test)\n",
    "        y_hat_test.append(y_hat)\n",
    "        res_test.append(residuals)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 12, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
